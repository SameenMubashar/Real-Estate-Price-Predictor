{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Libraries & Display Options\n",
    "\n",
    "This cell imports all required libraries for:\n",
    "- **Data handling**: `pandas`, `numpy`\n",
    "- **Preprocessing**: imputers, encoders, pipelines, column transformers\n",
    "- **Visualization**: `matplotlib`, `seaborn`\n",
    "- **Modeling**: train/test split, linear & tree-based regressors, metrics\n",
    "\n",
    "We also set a `pandas` display option to show **all columns** when printing DataFrames, which is helpful when inspecting encoded feature matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-19T18:38:53.802996Z",
     "iopub.status.busy": "2025-08-19T18:38:53.802605Z",
     "iopub.status.idle": "2025-08-19T18:38:55.894720Z",
     "shell.execute_reply": "2025-08-19T18:38:55.893650Z",
     "shell.execute_reply.started": "2025-08-19T18:38:53.802964Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# For Data manipulation and analytics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# For data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For model training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# setting display options for better viewing\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data & Initial Inspection\n",
    "\n",
    "We load the **Ames Housing**-style dataset from `train.csv`.  \n",
    "Then:\n",
    "- Show the **first 5 rows** to eyeball columns and values.\n",
    "- Print `df.info()` to see dtypes, non-null counts, and spot potential missing values.\n",
    "\n",
    "> Tip: If the path or filename differs, update `pd.read_csv('train.csv')` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T18:40:46.752105Z",
     "iopub.status.busy": "2025-08-19T18:40:46.751745Z",
     "iopub.status.idle": "2025-08-19T18:40:46.880050Z",
     "shell.execute_reply": "2025-08-19T18:40:46.879049Z",
     "shell.execute_reply.started": "2025-08-19T18:40:46.752079Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "df = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\n",
    "\n",
    "print(\"First 5 rows of the dataset\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nInformation of Dataset:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA: Distribution of SalePrice (Raw)\n",
    "\n",
    "Plot the raw distribution of the target `SalePrice` using a histogram with kernel density estimation (KDE).  \n",
    "Housing prices are usually **right-skewed**; verifying the skew helps justify a log transform later to stabilize variance and improve model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T18:40:53.513965Z",
     "iopub.status.busy": "2025-08-19T18:40:53.513600Z",
     "iopub.status.idle": "2025-08-19T18:40:54.018695Z",
     "shell.execute_reply": "2025-08-19T18:40:54.017630Z",
     "shell.execute_reply.started": "2025-08-19T18:40:53.513927Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of SalePrice\n",
    "plt.figure(figsize = (10,6))\n",
    "sns.histplot(df['SalePrice'], kde=True, bins=50)\n",
    "plt.title('Distribution of Sale Prices')\n",
    "plt.xlabel('Sale Price ($)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Target: `log1p(SalePrice)`\n",
    "\n",
    "Apply `np.log1p` to `SalePrice` (i.e., `log(1 + price)`).  \n",
    "This reduces right skew, makes errors more homoscedastic, and often improves linear model performance.\n",
    "\n",
    "> Note: To report metrics in original dollars, you’d need to `expm1` predictions and ground truth before scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T18:40:57.919733Z",
     "iopub.status.busy": "2025-08-19T18:40:57.919401Z",
     "iopub.status.idle": "2025-08-19T18:40:57.926968Z",
     "shell.execute_reply": "2025-08-19T18:40:57.926137Z",
     "shell.execute_reply.started": "2025-08-19T18:40:57.919707Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transformed_data = np.log1p(df['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA: Distribution of SalePrice (Log-Scaled)\n",
    "\n",
    "Re-plot the target after the log transform to confirm the distribution is now closer to **normal**.  \n",
    "A more symmetric distribution usually benefits regression models and simplifies residual analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T18:40:59.943287Z",
     "iopub.status.busy": "2025-08-19T18:40:59.942935Z",
     "iopub.status.idle": "2025-08-19T18:41:00.264594Z",
     "shell.execute_reply": "2025-08-19T18:41:00.263561Z",
     "shell.execute_reply.started": "2025-08-19T18:40:59.943258Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of transformed SalePrice as it was skewed\n",
    "plt.figure(figsize = (10,6))\n",
    "sns.histplot(transformed_data, kde=True, bins=50)\n",
    "plt.title('Distribution of Sale Prices')\n",
    "plt.xlabel('Sale Price ($)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commit Log-Scaled Target\n",
    "\n",
    "Replace `df['SalePrice']` with the log-transformed values so that the rest of the pipeline uses the stabilized target consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T18:41:29.674327Z",
     "iopub.status.busy": "2025-08-19T18:41:29.673910Z",
     "iopub.status.idle": "2025-08-19T18:41:29.682285Z",
     "shell.execute_reply": "2025-08-19T18:41:29.680789Z",
     "shell.execute_reply.started": "2025-08-19T18:41:29.674289Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df['SalePrice'] = transformed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Categorical Columns & Target Variable\n",
    "\n",
    "- Detect all **categorical** columns (dtype `object`) to plan encoding.\n",
    "- Define `target_col = 'SalePrice'` for clarity and reusability.\n",
    "\n",
    "This separation prepares us for a clean **feature/target** split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T18:44:40.638909Z",
     "iopub.status.busy": "2025-08-19T18:44:40.638504Z",
     "iopub.status.idle": "2025-08-19T18:44:40.647607Z",
     "shell.execute_reply": "2025-08-19T18:44:40.646160Z",
     "shell.execute_reply.started": "2025-08-19T18:44:40.638862Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Identify the target variable\n",
    "target_col = 'SalePrice'\n",
    "\n",
    "print(f\"Categorical features to encode: {list(categorical_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Features and Target\n",
    "\n",
    "- `y` is the **log-transformed** `SalePrice`.\n",
    "- `X` drops `Id` and `SalePrice` to keep only predictors.\n",
    "\n",
    "This establishes the modeling matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T18:50:04.255221Z",
     "iopub.status.busy": "2025-08-19T18:50:04.254836Z",
     "iopub.status.idle": "2025-08-19T18:50:04.262779Z",
     "shell.execute_reply": "2025-08-19T18:50:04.261817Z",
     "shell.execute_reply.started": "2025-08-19T18:50:04.255195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "target_col = 'SalePrice'\n",
    "y = df[target_col]\n",
    "X = df.drop(['Id', target_col], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA: Correlation Heatmap of Numerical Features with SalePrice\n",
    "\n",
    "Compute pairwise correlations for all **numerical features** and visualize their correlation with `SalePrice` using a heatmap.  \n",
    "- Darker colors show stronger positive or negative correlations.  \n",
    "- Annotated values provide exact correlation coefficients.  \n",
    "\n",
    "This helps quickly identify which numerical predictors (e.g., `OverallQual`, `GrLivArea`, `GarageCars`) are most strongly associated with housing prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA: Scatter Plots of Top Predictors vs. SalePrice (Log-Scaled)\n",
    "\n",
    "Visualize how the most correlated features relate to `SalePrice`.  \n",
    "We generate scatter plots for 10 top predictors (`OverallQual`, `GrLivArea`, `GarageCars`, `GarageArea`, `TotalBsmtSF`, `1stFlrSF`, `FullBath`, `YearBuilt`, `YearRemodAdd`, `GarageYrBlt`).  \n",
    "These plots help reveal **linear trends**, **outliers**, and whether relationships look suitable for regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T18:41:31.869823Z",
     "iopub.status.busy": "2025-08-19T18:41:31.869477Z",
     "iopub.status.idle": "2025-08-19T18:41:32.486386Z",
     "shell.execute_reply": "2025-08-19T18:41:32.484931Z",
     "shell.execute_reply.started": "2025-08-19T18:41:31.869797Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Correlation heatmap for numerical features\n",
    "plt.figure(figsize=(15,10))\n",
    "corr = df.corr(numeric_only=True)\n",
    "sns.heatmap(corr[['SalePrice']].sort_values(by='SalePrice', ascending=False), \n",
    "            annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlation of Numerical Features with SalePrice\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T18:43:19.233541Z",
     "iopub.status.busy": "2025-08-19T18:43:19.233173Z",
     "iopub.status.idle": "2025-08-19T18:43:21.591145Z",
     "shell.execute_reply": "2025-08-19T18:43:21.590097Z",
     "shell.execute_reply.started": "2025-08-19T18:43:19.233517Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "top_features = ['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', \n",
    "                'TotalBsmtSF', '1stFlrSF', 'FullBath', 'YearBuilt', \n",
    "                'YearRemodAdd', 'GarageYrBlt']\n",
    "\n",
    "plt.figure(figsize=(20, 25))\n",
    "\n",
    "for i, col in enumerate(top_features, 1):\n",
    "    plt.subplot(5, 2, i)  # 5 rows, 2 cols\n",
    "    sns.scatterplot(x=df[col], y=df['SalePrice'], alpha=0.6)\n",
    "    plt.title(f'{col} vs SalePrice')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('SalePrice')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T18:50:06.053528Z",
     "iopub.status.busy": "2025-08-19T18:50:06.053152Z",
     "iopub.status.idle": "2025-08-19T18:50:06.381657Z",
     "shell.execute_reply": "2025-08-19T18:50:06.380505Z",
     "shell.execute_reply.started": "2025-08-19T18:50:06.053500Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if 'GarageYrBlt' in X.columns and 'YearBuilt' in X.columns:\n",
    "    X['GarageYrBlt'] = X['GarageYrBlt'].fillna(X['YearBuilt'])\n",
    "\n",
    "numeric_pipe_top = Pipeline(steps=[\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "])\n",
    "\n",
    "preprocessor_top = ColumnTransformer(\n",
    "    transformers=[(\"num\", numeric_pipe_top, top_features)],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "# Fit/transform just the top features\n",
    "X_top_array = preprocessor_top.fit_transform(X)\n",
    "X_top = pd.DataFrame(X_top_array, columns=preprocessor_top.get_feature_names_out())\n",
    "\n",
    "# If you want correlations with SalePrice for these top features:\n",
    "corr_top = pd.concat([X_top, y.rename('SalePrice')], axis=1).corr(numeric_only=True)['SalePrice'].sort_values(ascending=False)\n",
    "print(corr_top.to_string())\n",
    "\n",
    "# Quick bar plot of their correlations\n",
    "plt.figure(figsize=(10,6))\n",
    "corr_top.drop('SalePrice').plot(kind='bar')\n",
    "plt.title('Correlation of Top Features with SalePrice')\n",
    "plt.ylabel('Correlation')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Train/Test Sets\n",
    "\n",
    "Create an 80/20 split with a fixed `random_state` for reproducibility.  \n",
    "We print counts to verify the split sizes.\n",
    "\n",
    "> Consistent splits enable **fair model comparisons**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T18:55:34.503575Z",
     "iopub.status.busy": "2025-08-19T18:55:34.503292Z",
     "iopub.status.idle": "2025-08-19T18:55:34.513992Z",
     "shell.execute_reply": "2025-08-19T18:55:34.512974Z",
     "shell.execute_reply.started": "2025-08-19T18:55:34.503555Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_top, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate: No NaNs After Preprocessing\n",
    "\n",
    "Count `NaN` values in train and test features.  \n",
    "This confirms imputers and encoders produced a fully numeric, NaN-free matrix compatible with scikit-learn estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T18:55:42.881589Z",
     "iopub.status.busy": "2025-08-19T18:55:42.881199Z",
     "iopub.status.idle": "2025-08-19T18:55:42.889405Z",
     "shell.execute_reply": "2025-08-19T18:55:42.888501Z",
     "shell.execute_reply.started": "2025-08-19T18:55:42.881563Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(np.isnan(X_train).sum()) \n",
    "print(np.isnan(X_test).sum())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Zoo: Train & Compare (LR, Ridge, Lasso, RF, GB)\n",
    "\n",
    "Define and train five models on the **same split**:\n",
    "- Linear Regression\n",
    "- Ridge Regression (L2 regularization)\n",
    "- Lasso Regression (L1 regularization, performs feature selection)\n",
    "- Random Forest (bagged trees; captures interactions; robust)\n",
    "- Gradient Boosting (sequential trees; often SOTA for tabular data)\n",
    "\n",
    "Collect **R²/MAE/RMSE** for each and print a **sorted leaderboard** by R².  \n",
    "This gives a concise, apples-to-apples comparison across approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T18:56:20.242628Z",
     "iopub.status.busy": "2025-08-19T18:56:20.242271Z",
     "iopub.status.idle": "2025-08-19T18:56:23.879630Z",
     "shell.execute_reply": "2025-08-19T18:56:23.878577Z",
     "shell.execute_reply.started": "2025-08-19T18:56:20.242602Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(alpha=10),\n",
    "    \"Lasso Regression\": Lasso(alpha=0.001, max_iter=5000),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=300, max_depth=15, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=500, learning_rate=0.05,\n",
    "                                                   max_depth=4, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    results.append([name, r2, mae, rmse])\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"R²\", \"MAE\", \"RMSE\"])\n",
    "print(results_df.sort_values(by=\"R²\", ascending=False).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Diagnostics: Actual vs Predicted (Per Model)\n",
    "\n",
    "Define a plotting function and generate one **scatter plot** per model:\n",
    "- X-axis: **Actual** (log) `SalePrice`\n",
    "- Y-axis: **Predicted** (log) `SalePrice`\n",
    "- Reference 45° line to gauge calibration\n",
    "\n",
    "Saved to PNG files for reporting.  \n",
    "These plots reveal **bias**, **spread**, and whether predictions cluster off the ideal line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T18:56:44.307993Z",
     "iopub.status.busy": "2025-08-19T18:56:44.306807Z",
     "iopub.status.idle": "2025-08-19T18:56:46.423764Z",
     "shell.execute_reply": "2025-08-19T18:56:46.422792Z",
     "shell.execute_reply.started": "2025-08-19T18:56:44.307956Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_actual_vs_pred(y_true, y_pred, title, save_path=None):\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.scatter(y_true, y_pred, alpha=0.6)\n",
    "    lims = [min(y_true.min(), y_pred.min()), max(y_true.max(), y_pred.max())]\n",
    "    plt.plot(lims, lims, '--r', linewidth=2)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Actual Sale Price')\n",
    "    plt.ylabel('Predicted Sale Price')\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    plot_actual_vs_pred(y_test, y_pred, f'{name}: Actual vs Predicted',\n",
    "                        save_path=f'{name.replace(\" \", \"_\").lower()}_actual_vs_pred.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps & Notes\n",
    "\n",
    "- **Cross-Validation**: Use `cross_validate` with `cv=5` to reduce variance from a single split.\n",
    "- **Hyperparameter Tuning**:\n",
    "  - Random Forest: `n_estimators`, `max_depth`, `min_samples_split`, `max_features`\n",
    "  - Gradient Boosting: `learning_rate`, `n_estimators`, `max_depth`, `subsample`\n",
    "- **Boosting Libraries**: Try **XGBoost**, **LightGBM**, or **CatBoost** for stronger tabular performance.\n",
    "- **Feature Engineering**:\n",
    "  - Interaction terms (e.g., quality × area)\n",
    "  - Age features (e.g., `YrSold - YearBuilt`, `YearRemodAdd` deltas)\n",
    "  - Neighborhood aggregates (median price by area)\n",
    "\n",
    "> Remember: Metrics are on the **log scale** here. For business-facing reporting, inverse-transform to price dollars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Kaggle Submission (Id, SalePrice)\n",
    "\n",
    "This cell:\n",
    "1) Loads the competition `test.csv`.  \n",
    "2) Applies the **same preprocessing** (ordinal/one-hot/median impute).  \n",
    "3) Selects the same **top-feature slice** used for training.  \n",
    "4) Trains the chosen model on **all training data** (for best final perf).  \n",
    "5) Predicts on test set, **inverse-transforms** from log scale (`expm1`).  \n",
    "6) Writes `submission.csv` with columns **Id, SalePrice**.\n",
    "\n",
    "Note: Kaggle evaluates RMSLE on logs, but the file you submit must contain **actual prices** (not log values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T19:09:43.108410Z",
     "iopub.status.busy": "2025-08-19T19:09:43.108077Z",
     "iopub.status.idle": "2025-08-19T19:09:45.638792Z",
     "shell.execute_reply": "2025-08-19T19:09:45.637612Z",
     "shell.execute_reply.started": "2025-08-19T19:09:43.108386Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")\n",
    "test_ids = test_df[\"Id\"].copy()\n",
    "\n",
    "preprocessor_top.fit(X)\n",
    "X_all_prepared = preprocessor_top.transform(X)\n",
    "X_test_prepared = preprocessor_top.transform(test_df.drop(columns=[\"Id\"]))\n",
    "\n",
    "feature_names_all = preprocessor_top.get_feature_names_out()\n",
    "valid_top_features = [\n",
    "    'OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'ExterQual',\n",
    "    'KitchenQual', 'BsmtQual', 'TotalBsmtSF', '1stFlrSF', 'FullBath',\n",
    "    'YearBuilt', 'YearRemodAdd', 'GarageFinish', 'TotRmsAbvGrd',\n",
    "    'Fireplaces', 'HeatingQC', 'MasVnrArea', 'PoolQC',\n",
    "    'GarageYrBlt', 'Condition1_Norm' \n",
    "]\n",
    "present = [f for f in valid_top_features if f in feature_names_all]\n",
    "top_features_indices = [np.where(feature_names_all == f)[0][0] for f in present]\n",
    "\n",
    "X_all_top = X_all_prepared[:, top_features_indices]\n",
    "X_test_top = X_test_prepared[:, top_features_indices]\n",
    "\n",
    "final_model = RandomForestRegressor(n_estimators=300, max_depth=15, random_state=42)\n",
    "\n",
    "final_model.fit(X_all_top, y)             \n",
    "y_test_pred_log = final_model.predict(X_test_top)\n",
    "\n",
    "y_test_pred = np.expm1(y_test_pred_log)    \n",
    "y_test_pred = np.maximum(y_test_pred, 0.0) \n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"Id\": test_ids,\n",
    "    \"SalePrice\": y_test_pred\n",
    "})\n",
    "\n",
    "submission_path = \"/kaggle/working/submission.csv\"\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(\"Saved:\", submission_path)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 868283,
     "sourceId": 5407,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
